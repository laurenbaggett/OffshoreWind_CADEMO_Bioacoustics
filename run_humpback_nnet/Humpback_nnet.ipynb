{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aafc292-525a-4c98-a9dc-668d1ea1c2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from AudioStreamDescriptor import XWAVhdr\n",
    "from xwav_functions import get_datetime\n",
    "\n",
    "# allow for dynamic memory allocation\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "921de5db-1820-4222-85c7-6f214ff6ff90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory growth enabled\n",
      "Processing file: CHNMS_NO_01_231105_154200_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231106_221127_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231107_202550_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231108_184012_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231109_165435_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231110_150857_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231111_132320_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231112_113742_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231113_095205_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231114_080627_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231115_062050_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231116_043512_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231118_010357_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231118_231820_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231119_213326_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231120_194748_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231121_180211_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231122_161633_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231123_143056_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231124_124518_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231125_105941_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231126_091403_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231127_072826_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231128_054248_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231130_021133_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231201_002556_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231201_224018_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231202_205441_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231203_190903_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231204_172326_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231205_153748_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231206_135211_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231207_120633_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231208_102056_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231209_083518_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231210_064941_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231211_050403_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231117_024935_df32.x.wav\n",
      "Processing file: CHNMS_NO_01_231129_035711_df32.x.wav\n",
      "Elasped Time: 3856.7767 seconds\n"
     ]
    }
   ],
   "source": [
    "# now run this for a directory of xwav files\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from AudioStreamDescriptor import XWAVhdr\n",
    "from xwav_functions import get_datetime\n",
    "\n",
    "# allow for dynamic memory allocation\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "print(\"GPU memory growth enabled\")\n",
    "\n",
    "# load Ann Allen model\n",
    "# model = hub.load('https://www.kaggle.com/models/google/humpback-whale/TensorFlow2/humpback-whale/1')\n",
    "model_path = r'C:\\Users\\HARP\\humpback_model'\n",
    "model = hub.load(model_path)\n",
    "th = 0 # threshold for presence/absence of humpbacks, can play around with this\n",
    "\n",
    "st_time = time.time()\n",
    "\n",
    "xwavDir = 'Z:/CHNMS/CHNMS_NO_01/CHNMS_NO_01_disk01_df32' # path to xwav files\n",
    "files = os.listdir(xwavDir)\n",
    "\n",
    "for file_name in files:\n",
    "        \n",
    "    # build the file path\n",
    "    input_path = os.path.join(xwavDir, file_name)\n",
    "    print(f\"Processing file: {file_name}\")\n",
    "    \n",
    "    waveform, sample_rate = tf.audio.decode_wav(tf.io.read_file(input_path))\n",
    "    \n",
    "    xwav = XWAVhdr(input_path) # Marie's function to read the header info\n",
    "    # Compute the number of samples in each raw file\n",
    "    bits_per_byte = 8\n",
    "    bytes_per_sample = xwav.xhd['NumChannels'] * \\\n",
    "                        xwav.xhd['BitsPerSample'] / bits_per_byte\n",
    "    raw_samples = [int(b / bytes_per_sample) for b in xwav.xhd['byte_length']]\n",
    "        \n",
    "    # Ensure the waveform has a batch dimension and channel dimension (e.g., shape [1, time_steps, channels])\n",
    "    waveform = tf.expand_dims(waveform, 0)  # Adds a batch dimension\n",
    "    if len(waveform.shape) == 2:  \n",
    "        waveform = tf.expand_dims(waveform, -1)  # Adds the channel dimension (shape becomes [1, time_steps, 1])\n",
    "    \n",
    "    # Define chunk size (number of raw files)\n",
    "    num_chunks = xwav.xhd[\"NumOfRawFiles\"]  \n",
    "    \n",
    "    # Function to process each chunk\n",
    "    def process_chunk(chunk_waveform):\n",
    "        context_step_samples = tf.cast(sample_rate, tf.int64)\n",
    "        score_fn = model.signatures['score']\n",
    "        scores = score_fn(waveform=chunk_waveform, context_step_samples=context_step_samples)\n",
    "        predictions = scores['scores'].numpy().flatten()  # Flatten to 1D\n",
    "        return predictions\n",
    "    \n",
    "    # List to hold the predictions\n",
    "    labels = np.array([])\n",
    "    starts = np.array([])\n",
    "    samp = np.array([])\n",
    "    spd = 60*60*24\n",
    "    \n",
    "    # Process each chunk\n",
    "    end = 0 # start at the beginning\n",
    "    for i in range(num_chunks):\n",
    "        start = end + 1\n",
    "        end = start + raw_samples[i]\n",
    "        chunk_waveform = waveform[:, start:end, :]  # Slice the waveform in chunks\n",
    "    \n",
    "        # Process the chunk\n",
    "        predictions = process_chunk(chunk_waveform)\n",
    "        np_predictions = np.array(predictions)\n",
    "        labels = np.append(labels,np_predictions)\n",
    "        sec = np.arange(0,len(predictions)-1 + 1)*3.92\n",
    "        st = [xwav.raw[\"dnumStart\"][i] + timedelta(seconds=s) for s in sec]\n",
    "        starts = np.append(starts,st)\n",
    "        samples = np.arange(0,len(predictions)-1 + 1)*(3.92*10000) + start\n",
    "        samp = np.append(samp,samples)\n",
    "        # result = 1 if np.any(np_predictions > th) else 0\n",
    "        # labels = np.append(labels,result)\n",
    "        # all_predictions.extend(predictions)  # if you want to save all of the predictions, not just +/- for the rf\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'dnumStart':starts,\n",
    "        'sampleStart':samp,\n",
    "        # 'dnumEnd':xwav.raw[\"dnumEnd\"],\n",
    "        'label':labels\n",
    "    })\n",
    "\n",
    "    savename = \"H:/Mysticetes/Humpback_NNET/hump_nnet_no_threshold_3.92s/CHNMS_NO_01/_\" + file_name[0:26] + \"Humback_NNET_3.92s_window.csv\"\n",
    "    df.to_csv(savename,index=False)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - st_time\n",
    "print(f\"Elasped Time: {elapsed_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1a109f-b34e-4018-9680-f63250606df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version classifying 1 raw file at a time! best option for timing, deals with noncontinuous data, gives no memory errors\n",
    "# for 320 data, 1 raw file is 43.75 seconds long\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from AudioStreamDescriptor import XWAVhdr\n",
    "from xwav_functions import get_datetime\n",
    "\n",
    "# allow for dynamic memory allocation\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "st_time = time.time()\n",
    "\n",
    "FILENAME = 'D:/Mysticetes/Humpback_NNET/CHNMS_NO_01_df32_testdata/CHNMS_NO_01_231110_150857_df32.x.wav'\n",
    "\n",
    "waveform, sample_rate = tf.audio.decode_wav(tf.io.read_file(FILENAME))\n",
    "\n",
    "xwav = XWAVhdr(FILENAME) # Marie's function to read the header info\n",
    "# Compute the number of samples in each raw file\n",
    "bits_per_byte = 8\n",
    "bytes_per_sample = xwav.xhd['NumChannels'] * \\\n",
    "                    xwav.xhd['BitsPerSample'] / bits_per_byte\n",
    "raw_samples = [int(b / bytes_per_sample) for b in xwav.xhd['byte_length']]\n",
    "\n",
    "# test wav file\n",
    "# FILENAME = 'gs://bioacoustics-www1/sounds/Cross_02_060203_071428.d20_7.wav'\n",
    "FILENAME = 'D:/Mysticetes/Humpback_NNET/CHNMS_NO_01_df32_testdata/CHNMS_NO_01_231110_150857_df32.x.wav'\n",
    "\n",
    "# load Ann Allen model\n",
    "model = hub.load('https://www.kaggle.com/models/google/humpback-whale/TensorFlow2/humpback-whale/1')\n",
    "\n",
    "# load the audio file\n",
    "waveform, sample_rate = tf.audio.decode_wav(tf.io.read_file(FILENAME))\n",
    "\n",
    "th = 0.5 # threshold for presence/absence of humpbacks\n",
    "\n",
    "# Ensure the waveform has a batch dimension and channel dimension (e.g., shape [1, time_steps, channels])\n",
    "waveform = tf.expand_dims(waveform, 0)  # Adds a batch dimension\n",
    "if len(waveform.shape) == 2:  # If it's mono audio (shape is [time_steps, 1])\n",
    "    waveform = tf.expand_dims(waveform, -1)  # Adds the channel dimension (shape becomes [1, time_steps, 1])\n",
    "\n",
    "# Define chunk size (number of raw files)\n",
    "num_chunks = xwav.xhd[\"NumOfRawFiles\"]  \n",
    "\n",
    "# Function to process each chunk\n",
    "def process_chunk(chunk_waveform):\n",
    "    context_step_samples = tf.cast(sample_rate, tf.int64)\n",
    "    score_fn = model.signatures['score']\n",
    "    scores = score_fn(waveform=chunk_waveform, context_step_samples=context_step_samples)\n",
    "    predictions = scores['scores'].numpy().flatten()  # Flatten to 1D\n",
    "    return predictions\n",
    "\n",
    "# List to hold the predictions\n",
    "all_predictions = []\n",
    "all_st_idx = np.array([])\n",
    "all_ed_idx = np.array([])\n",
    "labels = np.array([])\n",
    "\n",
    "# Process each chunk\n",
    "end = 0 # start at the beginning\n",
    "for i in range(num_chunks):\n",
    "    start = end + 1\n",
    "    end = start + raw_samples[i]\n",
    "    chunk_waveform = waveform[:, start:end, :]  # Slice the waveform in chunks\n",
    "\n",
    "    # Process the chunk\n",
    "    predictions = process_chunk(chunk_waveform)\n",
    "    np_predictions = np.array(predictions)\n",
    "    result = 1 if np.any(np_predictions > th) else 0\n",
    "    labels = np.append(labels,result)\n",
    "    # all_predictions.extend(predictions)  # Append predictions from this chunk\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'dnumStart':xwav.raw[\"dnumStart\"],\n",
    "    'dnumEnd':xwav.raw[\"dnumEnd\"],\n",
    "    'label':labels\n",
    "})\n",
    "\n",
    "df.to_csv('D:/Mysticetes/Humpback_NNET/CHNMS_test_results_NEW_samples_rawFiles.csv',index=False)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - st_time\n",
    "print(f\"Elasped Time: {elapsed_time:.4f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
